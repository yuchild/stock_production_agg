{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd47c8e5-091d-441c-8c69-a157d01f3d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c06de9be-0833-499e-859f-19c3f351be06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import multiprocessing\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from src import modules as f\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f11530b7-8037-42cf-8d26-e3030b661ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock set: \n",
      "{'GOOGL', 'OKE', 'AMGN', 'KMI', 'JPM', 'UNH', 'WFC', 'AAPL', 'GOOG', 'AEP', 'PM', 'MA', 'NRG', 'LLY', 'IBM', 'SW', 'PG', 'DIS', 'MSI', 'CMCSA', 'NEM', 'ABT', 'FWONK', 'PGR', 'AXP', 'DASH', 'TDG', 'AJG', 'NTRA', 'COST', 'SPGI', 'GS', 'MDLZ', 'XEL', 'AVGO', 'CEG', 'SRE', 'DUK', 'PEG', 'EA', 'LNG', '^VIX', 'NVDA', 'VZ', 'WMB', 'EXE', 'NFLX', 'EXC', 'TMO', 'PEP', 'HD', 'D', 'EOG', 'RBA.TO', 'ISRG', 'ORCL', 'CRM', 'META', 'SO', 'CVX', 'NEE', 'JNJ', 'TMUS', 'ALL', 'ACN', 'APH', 'WMT', 'KO', 'MRK', 'CSCO', 'WSM', 'PSX', 'ATO', 'CRH', 'BRK-B', 'SLB', 'TSLA', 'KMB', 'AMZN', 'NTNX', 'MSFT', 'COP', 'MO', 'PLTR', 'XOM', 'CL', 'ABBV', 'V', 'BSX', 'BAC', 'T', 'LII'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download, load, extract, model...\n",
    "interval = '1d'\n",
    "stock_set = f.download_interval_process(interval, 1)\n",
    "print(f'Stock set: \\n{stock_set}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e07532a6-0b04-49bd-95f2-6061ee9e73e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.make_table_features_process(stock_set, interval, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8e4bf89-6ffd-4f60-bdb8-9a900e2ac7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved combined dataframe to: ./data_transformed/all_1d_model_df.pkl\n"
     ]
    }
   ],
   "source": [
    "f.make_master_table(stock_set, interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d30897b1-c9bd-4c46-903e-983ce47a66b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n"
     ]
    },
    {
     "ename": "TerminatedWorkerError",
     "evalue": "A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {SIGSEGV(-11)}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxg_boost_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minterval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1d\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid_search_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/github/stock_production_agg/src/modules.py:515\u001b[0m, in \u001b[0;36mxg_boost_model\u001b[0;34m(interval, grid_search_on)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# Using n_jobs=-1 to leverage all available cores for the grid search.\u001b[39;00m\n\u001b[1;32m    507\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(pipeline, \n\u001b[1;32m    508\u001b[0m                            param_grid, \n\u001b[1;32m    509\u001b[0m                            cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    513\u001b[0m                            pre_dispatch\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2*n_jobs\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    514\u001b[0m                           )\n\u001b[0;32m--> 515\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifier__sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n\u001b[1;32m    517\u001b[0m best_pipeline \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[0;32m~/Documents/github/stock_production_agg/stkenv/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/github/stock_production_agg/stkenv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1020\u001b[0m     )\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/github/stock_production_agg/stkenv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1571\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1570\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1571\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/github/stock_production_agg/stkenv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    967\u001b[0m         )\n\u001b[1;32m    968\u001b[0m     )\n\u001b[0;32m--> 970\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    993\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/github/stock_production_agg/stkenv/lib/python3.12/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/github/stock_production_agg/stkenv/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/github/stock_production_agg/stkenv/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/github/stock_production_agg/stkenv/lib/python3.12/site-packages/joblib/parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[1;32m   1748\u001b[0m \n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[0;32m-> 1754\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/github/stock_production_agg/stkenv/lib/python3.12/site-packages/joblib/parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[1;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[1;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1789\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/github/stock_production_agg/stkenv/lib/python3.12/site-packages/joblib/parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[0;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/github/stock_production_agg/stkenv/lib/python3.12/site-packages/joblib/parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[0;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {SIGSEGV(-11)}"
     ]
    }
   ],
   "source": [
    "f.xg_boost_model(interval='1d', grid_search_on=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a1c221-4de9-4792-bb9a-a24337cb849c",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = 'nvda'.upper()\n",
    "interval = '1d'\n",
    "f.model_prospect(symbol, interval, build=False)\n",
    "df_val = f.model_validation(symbol, interval)\n",
    "correctly_predicted = df_val.dir_pred_match.sum()\n",
    "print(f'\\nCorrectly Predicted: {correctly_predicted}')\n",
    "entries_predicted = df_val.shape[0]\n",
    "print(f'Entries Predicted: {entries_predicted}')\n",
    "print(f'Percent Correct: {correctly_predicted / entries_predicted}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b31ef7-1ff2-405c-ab3f-e74ff66a8955",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0139d8e3-d3ea-45af-9658-82cd77ff7683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1f467e-f1bc-4fb4-a4e2-ff6bb84d489c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16348be7-8927-4091-9a31-1c9a427b9830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pmdarima statsmodels prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfb6f56-47ff-4e86-bf84-3744c6fa77e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from pmdarima.arima import auto_arima\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import math\n",
    "\n",
    "stock_symbol = 'AMD'.upper()\n",
    "interval = '1d'\n",
    "f.download(stock_symbol, interval)\n",
    "stock_data = f.load_raw(stock_symbol, interval)\n",
    "stock_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f377003-94a2-4366-bd56-ecb44077c311",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot close price\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.grid(True)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Close Prices')\n",
    "plt.plot(stock_data['close'])\n",
    "plt.title(f'{stock_symbol} closing price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e710a4f-8a26-4ea7-bdfb-d4ebdb9c1cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution of the dataset\n",
    "df_close = stock_data['close']\n",
    "df_close.plot(kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665cc7e3-f2ac-4221-8225-4d2b891d61f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test for staionarity\n",
    "def test_stationarity(timeseries):\n",
    "    #Determing rolling statistics\n",
    "    rolmean = timeseries.rolling(12).mean()\n",
    "    rolstd = timeseries.rolling(12).std()\n",
    "    #Plot rolling statistics:\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(timeseries, color='blue',label='Original')\n",
    "    plt.plot(rolmean, color='red', label='Rolling Mean')\n",
    "    plt.plot(rolstd, color='black', label = 'Rolling Std')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Rolling Mean and Standard Deviation')\n",
    "    plt.show(block=False)\n",
    "    print(\"Results of dickey fuller test\")\n",
    "    adft = adfuller(timeseries,autolag='AIC')\n",
    "    # output for dft will give us without defining what the values are.\n",
    "    #hence we manually write what values does it explains using a for loop\n",
    "    output = pd.Series(adft[0:4],index=['Test Statistics','p-value','No. of lags used','Number of observations used'])\n",
    "    for key,values in adft[4].items():\n",
    "        output['critical value (%s)'%key] =  values\n",
    "    print(output)\n",
    "test_stationarity(df_close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c47b2b8-98f0-4ed6-a056-567eda7db307",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To separate the trend and the seasonality from a time series, \n",
    "# we can decompose the series using the following code.\n",
    "result = seasonal_decompose(df_close, model='multiplicative', period = 30)\n",
    "fig = plt.figure()  \n",
    "fig = result.plot()  \n",
    "fig.set_size_inches(16, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fba8fd-7821-43e8-a732-43a8743ffabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if not stationary then eliminate trend\n",
    "#Eliminate trend\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10, 6\n",
    "df_log = np.log(df_close)\n",
    "moving_avg = df_log.rolling(12).mean()\n",
    "std_dev = df_log.rolling(12).std()\n",
    "plt.legend(loc='best')\n",
    "plt.title('Moving Average')\n",
    "plt.plot(std_dev, color =\"black\", label = \"Standard Deviation\")\n",
    "plt.plot(moving_avg, color=\"red\", label = \"Mean\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3122e977-ffdd-4ebb-8396-c52fd28081cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into train and training set\n",
    "train_data, test_data = df_log[3:int(len(df_log)*0.9)], df_log[int(len(df_log)*0.9):]\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.grid(True)\n",
    "plt.xlabel('Dates')\n",
    "plt.ylabel('Closing Prices')\n",
    "plt.plot(df_log, 'green', label='Train data')\n",
    "plt.plot(test_data, 'blue', label='Test data')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250cbcbb-6650-42dc-ae22-846fe637f8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autoARIMA = auto_arima(train_data, start_p=0, start_q=0,\n",
    "                      test='adf',       # use adftest to find optimal 'd'\n",
    "                      max_p=3, max_q=3, # maximum p and q\n",
    "                      m=1,              # frequency of series\n",
    "                      d=None,           # let model determine 'd'\n",
    "                      seasonal=False,   # No Seasonality\n",
    "                      start_P=0, \n",
    "                      D=0, \n",
    "                      trace=True,\n",
    "                      error_action='ignore',  \n",
    "                      suppress_warnings=True, \n",
    "                      stepwise=True)\n",
    "print(model_autoARIMA.summary())\n",
    "model_autoARIMA.plot_diagnostics(figsize=(15,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fb3c11-ec51-4bbf-9e5e-c2cbf75b0d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure training data is tz-naive and has BusinessDay frequency\n",
    "train_data = train_data.copy()\n",
    "train_data.index = train_data.index.tz_localize(None)\n",
    "train_data = train_data.asfreq('B')\n",
    "\n",
    "# If your data are in log scale and you wish to forecast on that scale, use trend='t' (drift)\n",
    "model = ARIMA(train_data, order=(1,1,2), trend='t')\n",
    "fitted = model.fit()\n",
    "print(fitted.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d487a9-117d-4dfb-99e4-ace92c9c7fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this flag: True if your model and data are in log scale; False if in level scale.\n",
    "log_data = True\n",
    "\n",
    "# ----- Prepare Training Data -----\n",
    "train_data = train_data.copy()\n",
    "train_data.index = train_data.index.tz_localize(None)\n",
    "# Force training data to have BusinessDay frequency.\n",
    "train_data = train_data.asfreq('B')  # Now train_data.index has frequency, e.g. \"<BusinessDay>\"\n",
    "\n",
    "# ----- Prepare Test Data -----\n",
    "freq = train_data.index.freq  # should be <BusinessDay>\n",
    "test_index = pd.date_range(\n",
    "    start=train_data.index[-1] + pd.Timedelta(days=1),\n",
    "    periods=len(test_data),\n",
    "    freq=freq\n",
    ")\n",
    "test_data = test_data.copy()\n",
    "test_data.index = test_index\n",
    "\n",
    "print(\"Training data last date:\", train_data.index[-1])\n",
    "print(\"Test data first date:\", test_data.index[0])\n",
    "assert test_data.index[0] > train_data.index[-1], \"Test data index does not extend training data!\"\n",
    "\n",
    "# ----- Update Model State -----\n",
    "fitted.model.data.orig_endog.index = train_data.index\n",
    "fitted.model.data.dates = train_data.index\n",
    "\n",
    "fitted_updated = fitted.append(test_data, refit=False)\n",
    "\n",
    "# ----- Forecast Simulation Using get_forecast -----\n",
    "forecast_steps = 321\n",
    "forecast_object = fitted_updated.get_forecast(steps=forecast_steps)\n",
    "fc_series = forecast_object.predicted_mean\n",
    "conf_int = forecast_object.conf_int(alpha=0.05)\n",
    "\n",
    "# Rename the CI columns (if necessary)\n",
    "conf_int.columns = ['lower', 'upper']\n",
    "\n",
    "# For debugging, print a summary of the CI values.\n",
    "print(\"CI summary:\\n\", conf_int.describe())\n",
    "\n",
    "# If the model is built on log-scale data, convert forecasts and intervals back to price levels.\n",
    "if log_data:\n",
    "    fc_series = np.exp(fc_series)\n",
    "    conf_int = np.exp(conf_int)\n",
    "    last_actual_value = np.exp(test_data.iloc[-1])\n",
    "else:\n",
    "    last_actual_value = test_data.iloc[-1]\n",
    "\n",
    "# Prepend the last observed test value so the forecast connects.\n",
    "fc_series_full = pd.concat([pd.Series([last_actual_value], index=[test_data.index[-1]]), fc_series])\n",
    "conf_int_full = pd.concat([\n",
    "    pd.DataFrame({\"lower\": [last_actual_value], \"upper\": [last_actual_value]}, index=[test_data.index[-1]]),\n",
    "    conf_int\n",
    "])\n",
    "\n",
    "# (Optional for debugging) – You could widen the CI band temporarily for visibility.\n",
    "# For example, multiply the difference by 3:\n",
    "# conf_int_full[\"upper\"] = fc_series_full + 3*(conf_int_full[\"upper\"] - fc_series_full)\n",
    "# conf_int_full[\"lower\"] = fc_series_full - 3*(fc_series_full - conf_int_full[\"lower\"])\n",
    "\n",
    "# ----- Plotting -----\n",
    "plt.figure(figsize=(10, 5), dpi=100)\n",
    "if log_data:\n",
    "    plt.plot(np.exp(train_data), label='Training Data', zorder=1)\n",
    "    plt.plot(np.exp(test_data), color='blue', label='Actual Stock Price', zorder=2)\n",
    "else:\n",
    "    plt.plot(train_data, label='Training Data', zorder=1)\n",
    "    plt.plot(test_data, color='blue', label='Actual Stock Price', zorder=2)\n",
    "\n",
    "# Fill the CI band.\n",
    "plt.fill_between(conf_int_full.index,\n",
    "                 conf_int_full[\"lower\"],\n",
    "                 conf_int_full[\"upper\"],\n",
    "                 color='lightgrey', alpha=0.5, label='95% CI', zorder=3)\n",
    "\n",
    "# Plot the forecast as a bold orange line.\n",
    "plt.plot(fc_series_full.index, fc_series_full,\n",
    "         color='orange', linewidth=3, label='Forecast', zorder=4)\n",
    "\n",
    "plt.title(f'{stock_symbol} Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel(f'{stock_symbol} Stock Price')\n",
    "plt.legend(loc='upper left', fontsize=8)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1472744a-9dd2-463a-91f0-d1ce71100106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810aab75-e3d0-4880-ae08-8b9b01bc5078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1587ace-39d3-4dd8-baac-69729d086bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (stkenv)",
   "language": "python",
   "name": "stkenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
